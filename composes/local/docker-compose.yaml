version: '3.5'

services:

# DB region
  mongo:
    image: mongo
    hostname: mongo
    ports:
      - 27017:27017

  mongo-express:
    image: mongo-express
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_URL: mongodb://mongo:27017/

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181
  
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CREATE_TOPICS: "ski-orders"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# tracing
  zipkin:
    image: ghcr.io/openzipkin/zipkin-slim:${TAG:-latest}
    container_name: zipkin
    environment:
      - JAVA_OPTS=-Xms128m -Xmx256m -XX:+ExitOnOutOfMemoryError
      - ZIPKIN_UI_LOGS_URL=http://localhost:5601/app/kibana#/discover?_a=(index:'logstash-*',query:(language:lucene,query:'{traceId}'))
    ports:
      - 9411:9411  
  
# ELK 
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0
    ports:
      - "9200:9200"
    environment:
      - "discovery.type=single-node"
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data:rw              # Persistence data

  logstash:
    image: docker.elastic.co/logstash/logstash:7.2.0
    ports:
      - "25826:25826"
      - "5044:5044"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro                # Pipeline configuration
#    restart: on-failure
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:7.2.0
    ports:
      - "5601:5601"
#    restart: on-failure
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.2.0
    volumes:
      - ./filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro # Configuration file
      - /var/lib/docker/containers:/var/lib/docker/containers:ro           # Docker logs
      - /var/run/docker.sock:/var/run/docker.sock:ro                       # Additional information about containers
      - ./filebeat/data:/usr/share/filebeat/data:rw                        # Persistence data
      - /var/lib/docker:/var/lib/docker:ro
      # - /var/run/docker.sock:/var/run/docker.sock
      # - ./filebeat.yml:/usr/share/filebeat/filebeat.yml
    command: filebeat -e -strict.perms=false
    user: root                                                             # Allow access to log files and docker.sock
    restart: on-failure
    depends_on:
      - logstash

# services
  equipment-api:
      image: equipment-api
      ports:
          - 6001:6001
      environment:      
        - "SPRING_PROFILES_ACTIVE=docker"
      labels:
        collect_logs_with_filebeat: "true"
        decode_log_event_to_json_object: "true"

  order-api:
      image: order-api
      ports:
          - 6002:6002
      environment:      
        - "SPRING_PROFILES_ACTIVE=docker"
      labels:
        collect_logs_with_filebeat: "true"
        decode_log_event_to_json_object: "true"

  order-consumer:
      image: order-consumer:0.0.2-SNAPSHOT
      ports:
          - 6003:6003
      environment:      
        - "SPRING_PROFILES_ACTIVE=docker"      
      labels:
        collect_logs_with_filebeat: "true"
        decode_log_event_to_json_object: "true"

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local
  esdata1:
    driver: local